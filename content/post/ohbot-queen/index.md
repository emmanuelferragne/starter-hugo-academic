+++
title = "Don't stop him now!"
subtitle = "Ohbot sings Queen song"
math = true

date = 2021-09-30T00:00:00
lastmod = 2021-09-30T00:00:00
draft = false


# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Admin"]

tags = ["Phonetics", "Music"]
summary = "Ohbot sings Queen song"
[image]
  # Caption (optional)
  #caption = "Photo by Vlah Dumitru on Unsplash"

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Top"

  # Show image only in page previews?
  preview_only = false

+++

In this video, the Ohbot Pi sings the intro of _Don't Stop Me Now_ by Queen. __Lip aperture__ was automatically computed from __voice signal amplitude__, and the Ohbot's __head goes up and down__ following the __pitch of the melody__. In the [Github repo](https://github.com/emmanuelferragne/ohbot-python/tree/master/examples/Pi/singLipSync), I uploaded the Matlab script (signal2Lips.m) I wrote for this video as well as the Pitch file (dontStopPitch.txt, obtained with the [Praat program](https://www.fon.hum.uva.nl/praat/)). Hopefully the comments in the script will clarify the whole process !

<iframe width="560" height="315" src="https://www.youtube.com/embed/4o_a5QzJy9I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



