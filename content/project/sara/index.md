+++
# Project title.
title = "SARA"

# Date this page was created.
date = 2025-10-08T00:00:00

# Project summary to display on homepage.
summary = "SARA: Sound Articulations Reinforce Acquisition"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["Research", "Phonetics"]

# Optional external URL for project (replaces project detail page).
external_link = ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references 
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = ""

# Links (optional).
#url_pdf = ""
#url_slides = ""
#url_video = "https://www.youtube.com/watch?v=cJJtYiWifbY"
#url_code = "https://github.com/ohbot/ohbot-python/tree/master/examples/ohbotOperaTutorial"

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
#url_custom = [{icon_pack = "fab", icon="twitter", name="Follow", url = "https://twitter.com/georgecushen"}]

# Featured image
# To use, add an image named `featured.jpg/png` to your project's folder. 
[image]
  # Caption (optional)
  #caption = "Photo by Juan Montana on Unsplash"
  
  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Center"
+++
- Project funded by Agence Nationale de la Recherche (ANR)
- **Years**: 2025-2028
- **Principal Investigator** : Emmanuel Ferragne

## Participants:
- ALTAE: Emmanuel Ferragne, Tacita Black, Anne Guyot Talbot, Hannah King, Alice Léger, Sylvain Navarro, Maud Pélissier, Franck Zumstein.
- IPNP: Catherine Oppenheim, Sylvain Charron, Clément Debacker, Maliesse Lui. 

**Summary**
Learning to pronounce English is often a daunting task for learners and yet is essential in order to be understood. While correct perception of foreign language sounds is generally considered necessary in order to produce them, accurate perception does not prevent persistent pronunciation difficulties in learners. They tend to use more familiar articulatory gestures which come from their native language but are unsuitable in the target language. The first aim of the SARA project is to analyse these transfer phenomena in production using real-time articulatory MRI. Secondly, the same technique will be used to provide learners with visual feedback of their own articulation as well as that of a native speaker model. We will test whether this rich visual representation of the speech organs improves learners’ articulatory accuracy compared to the more common (and less informative) visual feedback technique using ultrasound tongue imaging. Furthermore, while visual feedback seems to improve articulation, its impact on the perception of the targeted sounds, particularly the discrimination of difficult phonemic contrasts, remains to be determined. We will therefore use functional MRI of brain activity to examine the extent to which the perception of these contrasts relies on motor representations; and we will examine the benefits of articulatory training on perception. By analysing Francophone learners of English, the SARA project aims to answer the following questions: 1) Do learners transfer articulatory gestures from their native language to their foreign language? 2) What impact does varying the quantity of information provided in articulatory visual feedback to learners have on their acquisition? 3) Do better articulatory representations lead to better perception of non-native contrasts?

